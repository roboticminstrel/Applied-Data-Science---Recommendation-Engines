{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Implementing Recommender Systems for BoardGamesGeek.com"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "from IPython.display import display\n",
    "%matplotlib inline\n",
    "#line-by-line runtime comparison for easier code optimization.\n",
    "%load_ext line_profiler\n",
    "\n",
    "pd.set_option('display.max_rows',1000)\n",
    "\n",
    "elite = pd.read_csv('../inputs/boardgame-elite-users.csv')\n",
    "elite = elite.rename(columns = {'Compiled from boardgamegeek.com by Matt Borthwick':'UserID'})\n",
    "titles = pd.read_csv('../inputs/boardgame-titles.csv')\n",
    "titles = titles.rename(columns={'boardgamegeek.com game ID':'gameID'})\n",
    "frequent = pd.read_csv('../inputs/boardgame-frequent-users.csv')\n",
    "frequent = frequent.rename(columns = {'Compiled from boardgamegeek.com by Matt Borthwick':'UserID'})\n",
    "#load up the big dataset\n",
    "#users = pd.read_csv('../inputs/boardgame-users.csv')\n",
    "#users = users.rename(columns = {'Compiled from boardgamegeek.com by Matt Borthwick':'UserID'})\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Baseline Predictor\n",
    "This is the simplest predictor I'm making for the project. It doubles as a way to normalize the Ratings matrix R for more complex algorithms (like SVD) that require some kind of a way to fill missing ratings in the sparse matrix. Subtracting the baseline prediction from each value in R normalizes so that missing values can be set to 0.\n",
    "\n",
    "All this prediction does is use the user rating averages, total average rating, and average item ratings to come up with a believable first guess. Details are in section 2.1 of the paper linked in the exploratory notebook. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.base import BaseEstimator, RegressorMixin\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "class Base_Predictor(BaseEstimator,RegressorMixin):\n",
    "    def __init__(self, DAMPENING_TERM=25, dampening=False):\n",
    "        self._dampening_term = 25\n",
    "        self._dampening = dampening\n",
    "        \n",
    "    def fit(self, X, y):\n",
    "        self._mean = y.mean()\n",
    "        self._R = pd.concat([X,y],axis=1).pivot_table(index='UserID',columns='gameID',values='rating')\n",
    "        self._bu = self._R.apply(lambda row: self._user_base(row), axis=1)\n",
    "        self._bi = self._R.apply(lambda column: self._item_base(column))\n",
    "        \n",
    "    def _user_base(self, row):\n",
    "        \"\"\"(1/M+d)*bu is with the dampening factor. Without it's 1/M * bu. To find the way to add the \n",
    "        dampening factor as a scalar multiplication: \n",
    "            k*1/M(bu) = 1/M+d(bu)\n",
    "            k = M/M+d\"\"\"\n",
    "        bu = row.mean() - self._mean\n",
    "        if self._dampening:\n",
    "            num_items_user_reviewed = row[row.notnull()].size\n",
    "            damp_factor = num_items_user_reviewed/(num_items_user_reviewed+self._dampening_term)\n",
    "            bu*=damp_factor\n",
    "        return bu\n",
    "    \n",
    "    def _item_base(self, column):\n",
    "        users_that_reviewed_this_item = column[column.notnull()]\n",
    "        bu_for_users_that_reviewed_i = self._bu[users_that_reviewed_this_item.index].mean()\n",
    "        bi = users_that_reviewed_this_item.mean()-bu_for_users_that_reviewed_i-self._mean\n",
    "        if self._dampening:\n",
    "            num_users_reviewed_item = column[column.notnull()].size\n",
    "            damp_factor = num_users_reviewed_item/(num_users_reviewed_item+self._dampening_term)\n",
    "            bi*=damp_factor\n",
    "        return bi\n",
    "        \n",
    "    def predict(self, X):\n",
    "        return self._mean + self._bu[X.UserID].values + self._bi[X.gameID].values\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### A little Unit Testing for Sanity's sake.\n",
    "I just made a simple 3x3 test data set with one missing value. I ran through the calculations by hand, and set up a little battery of tests to make sure it all works. I print out the 3 pieces of info so you can see visually. There's TDD_test_X, the user, item pair I predict. TDD_train_X is the list of values at the bottom, the middle matrix is TDD_test_X blown up into the ratings matrix (with the missing value I'm testing for showing). As long as this cell compiles without triggering an assertion error, things are working fine."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>UserID</th>\n",
       "      <th>gameID</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   UserID  gameID\n",
       "0       3       6"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>7</td>\n",
       "      <td>4</td>\n",
       "      <td>8.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5</td>\n",
       "      <td>7</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>7</td>\n",
       "      <td>8</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   4  5    6\n",
       "1  7  4  8.0\n",
       "2  5  7  3.0\n",
       "3  7  8  NaN"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>UserID</th>\n",
       "      <th>gameID</th>\n",
       "      <th>rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>7.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>8.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>7.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2</td>\n",
       "      <td>6</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>7.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>8.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   UserID  gameID  rating\n",
       "0       1       4     7.0\n",
       "1       1       5     4.0\n",
       "2       1       6     8.0\n",
       "3       2       4     5.0\n",
       "4       2       5     7.0\n",
       "5       2       6     3.0\n",
       "6       3       4     7.0\n",
       "7       3       5     8.0"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "np.random.seed(42)\n",
    "\n",
    "test_ratings_matrix = pd.DataFrame(np.random.randint(1,10,size=(3,3)),columns=map(int,list('456')),index=map(int,list('123')))\n",
    "test_ratings_matrix.loc[3,6] = np.NaN\n",
    "#collapse test frame down the same format as our dataset. 3 columns, user\n",
    "TDD_train_X = test_ratings_matrix.stack().reset_index()\n",
    "TDD_train_X.columns = ['UserID','gameID','rating']\n",
    "TDD_test_X = pd.DataFrame(data={'UserID':[3],'gameID':[6]})\n",
    "display(TDD_test_X)\n",
    "display(test_ratings_matrix)\n",
    "display(TDD_train_X)\n",
    "\n",
    "def test_baseline_predictor():\n",
    "    predictor = Base_Predictor()\n",
    "    predictor.fit(TDD_train_X[['UserID','gameID']],TDD_train_X.rating)\n",
    "    assert predictor._mean == 6.125, \"The incorrect mean was calculated for the baseline test set\"\n",
    "    assert predictor._bu.tolist() == [0.20833333333333304,-1.125,1.375], \"The wrong bu values were calculated for the baseline test\"\n",
    "    assert predictor._bi.tolist() == [0.05555555555555536, 0.05555555555555536, -0.16666666666666607], \"incorrect bi was calculated for baseline test\"\n",
    "    assert predictor.predict(TDD_test_X).tolist() == [7.333333333333334], \"baseline prediction for the test value was incorrect\"\n",
    "        \n",
    "\n",
    "test_baseline_predictor()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## User-User Collaborative Filtering\n",
    "\n",
    "This is the system described in section 2.2 of the linked paper. The idea is that to predict the rating of user U and item I, you use the normalized average rating of the N most similar users to U who have reviewed item I. There are multiple similarity measures that can be used, and several other hyper paramters that can be tweaked that can be fed into the class constructor for testing and comparison. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.base import BaseEstimator, RegressorMixin\n",
    "\n",
    "def mean_normalize(row):\n",
    "    return row - row.mean()\n",
    "\n",
    "#mean normalize has already been used if this is ever applied.\n",
    "def z_normalize(row):\n",
    "    return row/row.std()\n",
    "\n",
    "class U_U_predictor(BaseEstimator, RegressorMixin):\n",
    "    \n",
    "    #ratings matrix from the actual training values\n",
    "    #_R \n",
    "    \n",
    "    #precomputing user's average ratings and std to save time later.\n",
    "    #_user_average_rating\n",
    "    #_user_standard_deviation\n",
    "    \n",
    "    #user similarity matrix (size user x user)\n",
    "    #_S\n",
    "    \n",
    "    #function that changes depending on selected similarity metric (cosine, pearson, spearman, etc.)\n",
    "    #_calculate_user_similarity\n",
    "    \n",
    "    #switches between equation 2.6 and 2.7 in the paper\n",
    "    #_normalize_to_z_scores\n",
    "    \n",
    "    #the paper suggests a dampening threshhold to keep users from sparse reviews getting rated as overly similar\n",
    "    #_pearson_threshold\n",
    "    \n",
    "    #how many nearest neighbors to look at when computing rating predictions\n",
    "    #_N_similar\n",
    "        \n",
    "    def __init__(self, similarity_type = 'pearson', normalize_to_z_scores=False, \n",
    "                 pearson_threshold=50, N_similar=10, use_negative_similarities = False):\n",
    "        self.normalize_to_z_scores = normalize_to_z_scores\n",
    "        self.pearson_threshold = pearson_threshold\n",
    "        self.N_similar = N_similar\n",
    "        self.similarity_type = similarity_type\n",
    "        self.use_negative_similarities = use_negative_similarities\n",
    "\n",
    "            \n",
    "    def fit(self,X,y):\n",
    "        if self.similarity_type == 'cosine':\n",
    "            self._calculate_user_similarity = self._cosine_similarity\n",
    "        else: self._calculate_user_similarity = self._pearson_r_similarity_vectorized\n",
    "        \n",
    "        self._calculate_ratings_matrix(X,y)\n",
    "        self._calculate_user_similarity_matrix_s_vector()\n",
    "        \n",
    "        if self.normalize_to_z_scores:\n",
    "            self._R = self._R.apply(z_normalize, axis=1)\n",
    "            \n",
    "    \n",
    "    def _calculate_ratings_matrix(self, X,y):\n",
    "        \"\"\"Calculates the n_user x n_user similarity matrix: _S\"\"\"\n",
    "        self._R = pd.concat([X,y],axis=1).pivot_table(index='UserID',columns='gameID',values='rating')\n",
    "        \n",
    "        #preprocessing to make user similarities easier to calculate\n",
    "        self._user_average_rating = self._R.mean(axis=1)\n",
    "        self._user_standard_deviation = self._R.std(axis=1)\n",
    "        \n",
    "        #normalize\n",
    "        self._R = self._R.apply(mean_normalize, axis=1)\n",
    "        \n",
    "        \n",
    "    def _calculate_user_similarity_matrix_s_vector(self):\n",
    "        \"\"\"top level user similarity _S calculation function. To save time I initially set it up as\n",
    "        an N*(N_1)/2 triangle calculation instead of doing the full N^2 user, user calculation. Given\n",
    "        the current vector implementation, this may be a fair bit of obfuscation for a small amount of\n",
    "        benefit, it may be worth timing both implementations to see how time is actually being saved.\"\"\"\n",
    "        \n",
    "        #initialize our similarity matrix _S, and our temp numpy matrix we'll be using while calculating.\n",
    "        self._S = pd.DataFrame(index=self._R.index, columns = self._R.index.rename('User_Prime_ID'), data=0.0)\n",
    "        temp = np.full(self._S.shape,np.nan)\n",
    "        \n",
    "        #We have a user x user matrix of similarity values, but we don't need to do the main diagonal (user1 x user1\n",
    "        #will always have 1.0) and since the top and bottom diagonals are identical (since user1xuser2 = user2xuser1)\n",
    "        #we only bother calculating along the upper triangle. We go row by row, the row sizes decrease as we go.\n",
    "        for index,user1 in enumerate(self._R.index[:-1]):\n",
    "            user2s = self._R.index[index+1:].copy()\n",
    "            temp[index,index+1:] = self._calculate_user_similarity(user1,index,user2s)\n",
    "            \n",
    "        #now that we have the upper triangle values, all we have to do is mirror it to the bottom and we're done.\n",
    "        i_lower = np.tril_indices(temp.shape[0], -1)\n",
    "        temp[i_lower] = temp.T[i_lower] \n",
    "        #turn our numpy temp matrix back into a dataframe.\n",
    "        self._S = pd.DataFrame(temp, columns=self._S.columns, index=self._S.index)\n",
    "        #I decided I wanted 0.0 for user x user similarity, not NA.\n",
    "        self._S = self._S.fillna(0.0)\n",
    "        \n",
    "            \n",
    "    def _pearson_r_similarity_vectorized(self,user1,user1_index,user2s):\n",
    "        \"\"\"Calculates user1 similarity with other users\n",
    "        Parameters\n",
    "        ----------\n",
    "        user1 : int identifier for a user\n",
    "        user1_index : index position for where user1 appears in the index of _R\n",
    "        user2s : array, shape [n_users]\n",
    "        \n",
    "        Returns\n",
    "        -------\n",
    "        ret : array of float, shape = [n_users]. \n",
    "            corresponds to the ordered similarity values for each user 2 in user1's \n",
    "            row of the similarity matrix.\n",
    "        \"\"\"\n",
    "        \n",
    "        #get our initial user reviews from the review matrix\n",
    "        user2_ratings = self._R.iloc[user1_index+1:].as_matrix().copy()\n",
    "        user1_base_ratings = self._R.iloc[user1_index].as_matrix().copy()\n",
    "        \n",
    "        #we need a matrix for user1 review ratings. Each row is initialized to user1 reviews, below we zero out all\n",
    "        #games that user1 and the user2 for that row haven't both reviewed.\n",
    "        user1_ratings =  np.tile(user1_base_ratings, (user2_ratings.shape[0], 1))\n",
    "        \n",
    "        #find where user1 and user2s have reviewed items. (left half is a bool vector, right is a bool matrix).\n",
    "        #End matrix has each row as a boolean vector showing which items both user1 and the user2 for that row reviewed  \n",
    "        #We're reversing since we want False where both users reviewed the same item, and True elsewhere.\n",
    "        mask = (np.isnan(user1_base_ratings) | np.isnan(user2_ratings))\n",
    "\n",
    "        #Zero out all entries user 1 and 2 for each row pair haven't both reviewed. (Reviews have already been \n",
    "        #mean normalized, so this won't throw off the corr calculation)    \n",
    "        user2_ratings[mask] = 0.0\n",
    "        user1_ratings[mask] = 0.0\n",
    "        \n",
    "        #to pevent overly high similarities between users with few reviews in common, a dampening factor of\n",
    "        #min(N/50,1) is applied, where N is the number of items both have reviewed.\n",
    "        num_items = np.sum(~mask,axis=1)\n",
    "        dampening = (num_items/self.pearson_threshold).clip(0,1)\n",
    "        \n",
    "        #pearsonr is cov(1,2)/sqrt(Var(1)*Var(2)). This is just a vectorized implementation, doing row-wise dot \n",
    "        #products between two vectors.\n",
    "        variance1 = (user1_ratings * user1_ratings).sum(axis=1)\n",
    "        variance2 = (user2_ratings * user2_ratings).sum(axis=1)\n",
    "        denom = np.sqrt(variance1*variance2)\n",
    "        covariance = (user1_ratings * user2_ratings).sum(axis=1)\n",
    "\n",
    "        #catch any divide by 0 errors. Any user2s with 0 variance will produce a NaN.\n",
    "        with np.errstate(divide='ignore',invalid='ignore'):\n",
    "            ret = (dampening*covariance)/denom\n",
    "            ret[np.isnan(ret)] = 0.0\n",
    "            \n",
    "        return ret\n",
    "        \n",
    "    def _cosine_similarity(self):\n",
    "        pass\n",
    "    \n",
    "    def predict(self,X):\n",
    "        \"\"\"Calculates predicted reviews for user,gameID feature pairs X\n",
    "        ----------\n",
    "        X : array-like, shape (n_units, 2)\n",
    "        \n",
    "        Returns\n",
    "        -------\n",
    "        ret : array of float, shape = [n_units]. \n",
    "            corresponds to the ordered predictions for each feature pair in X.\n",
    "        \"\"\"\n",
    "        #add a new column to X for the predictions we're about to make.\n",
    "        output = pd.concat([X,pd.DataFrame(data=np.full(X.shape[0],np.nan),\n",
    "                                           columns=['rating'],index=X.index)],axis=1)\n",
    "        \n",
    "        #flag to account for pd.DataFrame.apply running twice the first iteration and messing up my code\n",
    "        self._apply_first_flag = True\n",
    "        \n",
    "        #group by UserID and predict for all games at once for each user. \n",
    "        output = output.groupby('UserID').apply(self.predict_by_user_vector)\n",
    "        return output.rating.values\n",
    "        \n",
    "\n",
    "    def predict_by_user_vector(self, row):\n",
    "        \"\"\"Calculates predicted reviews for user,gameID feature pairs X\n",
    "        ----------\n",
    "        X : pandas df, shape (n_games, 3), UserID, gameID, rating\n",
    "        \n",
    "        Returns\n",
    "        -------\n",
    "        row : pandas df, shape (n_games, 3)\n",
    "            input df with rating column filled in with prediction values\n",
    "        \"\"\"\n",
    "        user = row.iloc[0,0]\n",
    "        \n",
    "        #pd.DataFrame.apply runs the first group twice to see if it can optimize. If it's already ran on the current\n",
    "        #user (e.g, the second iteration of the loop) then skip.\n",
    "        if self._apply_first_flag:\n",
    "            self._apply_first_flag = False\n",
    "            return\n",
    "\n",
    "        user_average = self._user_average_rating[user]\n",
    "        \n",
    "        #Users with 0 standard deviation should automatically predict their average for any game. This make intuitive\n",
    "        #sense, but it also breaks my code if it's left to run with this edge case.\n",
    "        if self._user_standard_deviation[user] == 0.0:\n",
    "            row.rating = user_average\n",
    "            return row\n",
    "        \n",
    "        N = self.N_similar\n",
    "        \n",
    "        #this is a matrix where each row is for one of the games we're predicting, and each column is a user.\n",
    "        games_reviewed = self._R.loc[:,row.gameID].as_matrix().T.copy()\n",
    "        \n",
    "        #matrix of masks to get users that have reviewed a given game.\n",
    "        who_reviewed_which_games = ~np.isnan(games_reviewed)\n",
    "        \n",
    "        #get the similarity matrix. Each row is the user's similarity to all other users, with all the users who \n",
    "        #didn't review that row's gameID set to zero (so we don't count them)\n",
    "        user_similarity_vector = self._S.loc[user,:].as_matrix().copy()\n",
    "        user_similarity_matrix = np.tile(user_similarity_vector,(row.gameID.size,1))\n",
    "        user_similarity_matrix[~who_reviewed_which_games] = 0.0\n",
    "\n",
    "        number_of_games = row.gameID.size\n",
    "        \n",
    "        #get the indices for the N users with the highest similarity that also reviewed each game.\n",
    "        \n",
    "        if self.use_negative_similarities:\n",
    "            index = np.argpartition(abs(user_similarity_matrix),-N,axis=1)[:,-N:]\n",
    "        else:\n",
    "            index = np.argpartition(user_similarity_matrix,-N,axis=1)[:,-N:]\n",
    "        \n",
    "        #Use the indices to get the games x N matrix where each row is the user similarities for a given game.\n",
    "        similarity_matrix = user_similarity_matrix[np.arange(number_of_games).reshape(number_of_games,1),index]\n",
    "        #Use the indices to get the games x N matrix where each row is the top N similar users normalized rating for\n",
    "        #the game that row corresponds to. \n",
    "        norm_ratings_matrix = games_reviewed[np.arange(number_of_games).reshape(number_of_games,1),index]\n",
    "        \n",
    "        user_std = self._get_user_std(user)\n",
    "                \n",
    "        #For some N_nearest values, unusual users, etc. it may be that there aren't enough similar users\n",
    "        #who have reviewed a given game. This basically sets the N_Nearest down to the highest value for\n",
    "        #that game, user pair before running the final calculation. \n",
    "        N = N - np.isnan(norm_ratings_matrix).sum(axis=1)\n",
    "        norm_ratings_matrix[np.isnan(norm_ratings_matrix)] = 0.0\n",
    "        \n",
    "        estimated_user_reviews = user_average + (similarity_matrix * norm_ratings_matrix).sum(axis=1)*(user_std/N)\n",
    "\n",
    "        row.rating = estimated_user_reviews\n",
    "        \n",
    "        return row\n",
    "  \n",
    "    def _get_user_std(self,user):\n",
    "        \"\"\"Calculates std for user.\n",
    "        ----------\n",
    "        user : int, corresponding to a user ID in _R.\n",
    "        \n",
    "        Returns\n",
    "        -------\n",
    "        user_std : float, precalculated std. If z score normalization is off, then just return 1.0. \n",
    "        \"\"\"\n",
    "        user_std = 1.0\n",
    "        if(self.normalize_to_z_scores):\n",
    "            user_std = self._user_standard_deviation[user]\n",
    "        return user_std\n",
    "    \n",
    "\n",
    "    ####################################################################\n",
    "    #Naive testing functions. These are simple, non vectorized implementations I used to get a handle on the\n",
    "    #algorithms, and to test my more complicated optimized implementations. \n",
    "    ####################################################################\n",
    "    def naive_person_r_calc(self,u1,u2):\n",
    "        u1 = self._R.loc[user1].copy()\n",
    "        u2 = self._R.loc[user2].copy()\n",
    "\n",
    "        u1mean = u1.mean()\n",
    "        u2mean = u2.mean()\n",
    "\n",
    "        i1 = set(u1.dropna().index.tolist())\n",
    "        i2 = set(u2.dropna().index.tolist())\n",
    "        shared = i1.intersection(i2)\n",
    "\n",
    "        u1 = u1.loc[shared].sort_index()\n",
    "        u2 = u2.loc[shared].sort_index()\n",
    "\n",
    "        u1 -= u1mean\n",
    "        u2 -= u2mean\n",
    "\n",
    "        return np.dot(u1,u2)/np.sqrt(np.dot(u1,u1)*(np.dot(u2,u2)))\n",
    "    \n",
    "    \n",
    "    def _naive_single_predict_function(self, user, game):\n",
    "        user_mean = self._user_average_rating[user]\n",
    "        N = self.N_similar\n",
    "    \n",
    "        #nearest users IDs are the index of this series, s(u,u') is the values. It's filtered so only users\n",
    "        #who have also rated the game in question are considered. \n",
    "        N_nearest_similar = self._S[user][self._R[game].notnull()].nlargest(N)\n",
    "    \n",
    "        #vectors for most similar user information\n",
    "        similar_users_means = self._user_average_rating[N_nearest_similar.index].values\n",
    "        similar_users_item_ratings = self._R.loc[N_nearest_similar.index, game].values\n",
    "    \n",
    "        user_std = self._get_user_std(user)\n",
    "    \n",
    "        prediction = user_mean + ((user_std/N) * np.dot(N_nearest_similar.values,similar_users_item_ratings))\n",
    "    \n",
    "        return prediction\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_X, test_X, train_y,test_y = train_test_split(elite[['UserID','gameID']],elite.rating,test_size=.3,random_state=42)\n",
    "\n",
    "predictor = U_U_predictor()\n",
    "predictor.fit(train_X,train_y)\n",
    "\n",
    "predictor_with_z = U_U_predictor(normalize_to_z_scores=True)\n",
    "predictor_with_z.fit(train_X,train_y)\n",
    "\n",
    "def test_user_user_similarity_matrix_vector_function():\n",
    "    predictor = U_U_predictor()\n",
    "    predictor._calculate_ratings_matrix(train_X,train_y)\n",
    "    predictor.fit(train_X,train_y)\n",
    "    S = pd.read_pickle('user_S')\n",
    "    \n",
    "    #making sure that whatever method I'm using to calculate S, that it roughly equals my established baseline using\n",
    "    #a naive calculation that I picked. \n",
    "    assert S.size==np.count_nonzero(np.isclose(S, predictor._S, rtol=1e-07, atol=1e-010, equal_nan=True)),\"Similarity matrix was incorrectly calculated with PearsonR.\"\n",
    "\n",
    "\n",
    "def test_predict_function(predict):\n",
    "    naive_test_predict = []\n",
    "    num_to_test = 10\n",
    "    for index,row in test_X.iloc[:num_to_test].iterrows():\n",
    "        naive_prediction = predict._naive_single_predict_function(row.UserID,row.gameID)\n",
    "        naive_test_predict.append(naive_prediction)\n",
    "        \n",
    "    vector_test_predict = predict.predict(test_X.iloc[:num_to_test])\n",
    "\n",
    "    assert (np.isclose(naive_test_predict,vector_test_predict,rtol=1e-07).all()), \"Assert failed with z = {}\".format(predictor_with_z.normalize_to_z_scores)\n",
    "    \n",
    "\n",
    "def test_for_full_output():\n",
    "    predictor.fit(train_X,train_y)\n",
    "\n",
    "    predict = predictor.predict(test_X)\n",
    "\n",
    "    a = test_X.shape[0]\n",
    "    b = predict.size\n",
    "\n",
    "    assert a == b, \"there aren't as many predictions as there were rows in the feature set\"\n",
    "\n",
    "test_user_user_similarity_matrix_vector_function()\n",
    "test_predict_function(predictor)\n",
    "test_predict_function(predictor_with_z)\n",
    "test_for_full_output()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Scratch cell for timing and profiling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 588 ms, sys: 0 ns, total: 588 ms\n",
      "Wall time: 589 ms\n"
     ]
    }
   ],
   "source": [
    "#was 189 seconds\n",
    "#was 97 seconds. \n",
    "#was 49 seconds\n",
    "#calling it good at .8 seconds\n",
    "#predict is about .6s.\n",
    "\n",
    "train_X, test_x, train_y,test_y = train_test_split(elite[['UserID','gameID']],elite.rating,test_size=.3,random_state=42)\n",
    "\n",
    "predictor = U_U_predictor()\n",
    "#%lprun -f predictor.fit predictor.fit(train_X,train_y)\n",
    "predictor.fit(train_X,train_y)\n",
    "\n",
    "%time predictions = predictor.predict(test_x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Selection and Error checking\n",
    "\n",
    "Now that I've gotten some models built out, I can use Sklearn's framework to check out different prediction systems, compare RMSE, and see what kind of model works the best with this dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.30322536673\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "predictor = Base_Predictor()\n",
    "train_X, test_x, train_y,test_y = train_test_split(elite[['UserID','gameID']],elite.rating,test_size=.3,random_state=42)\n",
    "predictor.fit(train_X,train_y)\n",
    "\n",
    "predictions = predictor.predict(test_x)\n",
    "\n",
    "mse = mean_squared_error(predictions,test_y)\n",
    "print(np.sqrt(mse))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=4, error_score='raise',\n",
       "       estimator=U_U_predictor(N_similar=10, normalize_to_z_scores=False, pearson_threshold=50,\n",
       "       similarity_type='pearson', use_negative_similarities=False),\n",
       "       fit_params=None, iid=True, n_jobs=1,\n",
       "       param_grid=[{'normalize_to_z_scores': [True, False]}, {'N_similar': array([ 2,  4,  6,  8, 10, 12, 14, 16, 18, 20]), 'use_negative_similarities': [False]}, {'N_similar': array([ 8, 11, 14, 17, 20, 23, 26, 29, 32, 35, 38]), 'use_negative_similarities': [True]}],\n",
       "       pre_dispatch='2*n_jobs', refit=True, return_train_score='warn',\n",
       "       scoring='neg_mean_squared_error', verbose=0)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "parameter_candidates = [\n",
    "  {'normalize_to_z_scores': [True,False]},\n",
    "  {'N_similar': np.arange(2,21,2), 'use_negative_similarities': [False]},\n",
    "  {'N_similar': np.arange(8,39,3), 'use_negative_similarities': [True]}\n",
    "]\n",
    "\n",
    "clf = GridSearchCV(estimator = U_U_predictor(), param_grid = parameter_candidates, n_jobs=1, \n",
    "                   scoring='neg_mean_squared_error', cv=4)\n",
    "\n",
    "clf.fit(train_X, train_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best score for data1: 1.73485927576\n",
      "Use Z normalizing?:  True\n",
      "Best N_similar: 10\n",
      "Use use_negative_similarities?:  False\n"
     ]
    }
   ],
   "source": [
    "print('Best score for data1:', -clf.best_score_) \n",
    "print('Use Z normalizing?: ',clf.best_estimator_.normalize_to_z_scores) \n",
    "print('Best N_similar:',clf.best_estimator_.N_similar)\n",
    "print('Use use_negative_similarities?: ',clf.best_estimator_.use_negative_similarities)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "scores = cross_val_score(U_U_predictor(normalize_to_z_scores=True,N_similar=10), \n",
    "                         train_X, train_y, cv=5, scoring='neg_mean_squared_error')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.25584900521\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "predictor = U_U_predictor(normalize_to_z_scores=True,N_similar=10, use_negative_similarities=False)\n",
    "train_X, test_x, train_y,test_y = train_test_split(elite[['UserID','gameID']],elite.rating,test_size=.3,random_state=42)\n",
    "predictor.fit(train_X,train_y)\n",
    "\n",
    "predictions = predictor.predict(test_x)\n",
    "\n",
    "mse = mean_squared_error(predictions,test_y)\n",
    "print(np.sqrt(mse))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "scores = cross_val_score(Base_Predictor(), train_X, train_y, cv=5, scoring='neg_mean_squared_error')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.7040152706232921"
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "-(scores.mean())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
