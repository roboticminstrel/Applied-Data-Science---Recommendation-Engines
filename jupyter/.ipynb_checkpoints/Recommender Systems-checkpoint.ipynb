{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Implementing Recommender Systems for BoardGamesGeek.com"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The line_profiler extension is already loaded. To reload it, use:\n",
      "  %reload_ext line_profiler\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "from IPython.display import display\n",
    "%matplotlib inline\n",
    "#line-by-line runtime comparison for easier code optimization.\n",
    "%load_ext line_profiler\n",
    "\n",
    "pd.set_option('display.max_rows',1000)\n",
    "\n",
    "elite = pd.read_csv('../inputs/boardgame-elite-users.csv')\n",
    "elite = elite.rename(columns = {'Compiled from boardgamegeek.com by Matt Borthwick':'UserID'})\n",
    "titles = pd.read_csv('../inputs/boardgame-titles.csv')\n",
    "titles = titles.rename(columns={'boardgamegeek.com game ID':'gameID'})\n",
    "frequent = pd.read_csv('../inputs/boardgame-frequent-users.csv')\n",
    "frequent = frequent.rename(columns = {'Compiled from boardgamegeek.com by Matt Borthwick':'UserID'})\n",
    "#load up the big dataset\n",
    "#users = pd.read_csv('../inputs/boardgame-users.csv')\n",
    "#users = users.rename(columns = {'Compiled from boardgamegeek.com by Matt Borthwick':'UserID'})\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Baseline Predictor\n",
    "This is the simplest predictor I'm making for the project. It doubles as a way to normalize the Ratings matrix R for more complex algorithms (like SVD) that require some kind of a way to fill missing ratings in the sparse matrix. Subtracting the baseline prediction from each value in R normalizes so that missing values can be set to 0.\n",
    "\n",
    "All this prediction does is use the user rating averages, total average rating, and average item ratings to come up with a believable first guess. Details are in section 2.1 of the paper linked in the exploratory notebook. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.base import BaseEstimator, RegressorMixin\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "class Base_Predictor(BaseEstimator,RegressorMixin):\n",
    "    def __init__(self, DAMPENING_TERM=25, dampening=False):\n",
    "        self._dampening_term = 25\n",
    "        self._dampening = dampening\n",
    "        \n",
    "    def fit(self, X, y):\n",
    "        self._mean = y.mean()\n",
    "        self._R = pd.concat([X,y],axis=1).pivot_table(index='UserID',columns='gameID',values='rating')\n",
    "        self._bu = self._R.apply(lambda row: self._user_base(row), axis=1)\n",
    "        self._bi = self._R.apply(lambda column: self._item_base(column))\n",
    "        \n",
    "    def _user_base(self, row):\n",
    "        \"\"\"(1/M+d)*bu is with the dampening factor. Without it's 1/M * bu. To find the way to add the \n",
    "        dampening factor as a scalar multiplication: \n",
    "            k*1/M(bu) = 1/M+d(bu)\n",
    "            k = M/M+d\"\"\"\n",
    "        bu = row.mean() - self._mean\n",
    "        if self._dampening:\n",
    "            num_items_user_reviewed = row[row.notnull()].size\n",
    "            damp_factor = num_items_user_reviewed/(num_items_user_reviewed+self._dampening_term)\n",
    "            bu*=damp_factor\n",
    "        return bu\n",
    "    \n",
    "    def _item_base(self, column):\n",
    "        users_that_reviewed_this_item = column[column.notnull()]\n",
    "        bu_for_users_that_reviewed_i = self._bu[users_that_reviewed_this_item.index].mean()\n",
    "        bi = users_that_reviewed_this_item.mean()-bu_for_users_that_reviewed_i-self._mean\n",
    "        if self._dampening:\n",
    "            num_users_reviewed_item = column[column.notnull()].size\n",
    "            damp_factor = num_users_reviewed_item/(num_users_reviewed_item+self._dampening_term)\n",
    "            bi*=damp_factor\n",
    "        return bi\n",
    "        \n",
    "    def predict(self, X):\n",
    "        return self._mean + self._bu[X.UserID].values + self._bi[X.gameID].values\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### A little Unit Testing for Sanity's sake.\n",
    "I just made a simple 3x3 test data set with one missing value. I ran through the calculations by hand, and set up a little battery of tests to make sure it all works. I print out the 3 pieces of info so you can see visually. There's TDD_test_X, the user, item pair I predict. TDD_train_X is the list of values at the bottom, the middle matrix is TDD_test_X blown up into the ratings matrix (with the missing value I'm testing for showing). As long as this cell compiles without triggering an assertion error, things are working fine."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>UserID</th>\n",
       "      <th>gameID</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   UserID  gameID\n",
       "0       3       6"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>7</td>\n",
       "      <td>4</td>\n",
       "      <td>8.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5</td>\n",
       "      <td>7</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>7</td>\n",
       "      <td>8</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   4  5    6\n",
       "1  7  4  8.0\n",
       "2  5  7  3.0\n",
       "3  7  8  NaN"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>UserID</th>\n",
       "      <th>gameID</th>\n",
       "      <th>rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>7.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>8.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>7.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2</td>\n",
       "      <td>6</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>7.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>8.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   UserID  gameID  rating\n",
       "0       1       4     7.0\n",
       "1       1       5     4.0\n",
       "2       1       6     8.0\n",
       "3       2       4     5.0\n",
       "4       2       5     7.0\n",
       "5       2       6     3.0\n",
       "6       3       4     7.0\n",
       "7       3       5     8.0"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "np.random.seed(42)\n",
    "\n",
    "test_ratings_matrix = pd.DataFrame(np.random.randint(1,10,size=(3,3)),columns=map(int,list('456')),index=map(int,list('123')))\n",
    "test_ratings_matrix.loc[3,6] = np.NaN\n",
    "#collapse test frame down the same format as our dataset. 3 columns, user\n",
    "TDD_train_X = test_ratings_matrix.stack().reset_index()\n",
    "TDD_train_X.columns = ['UserID','gameID','rating']\n",
    "TDD_test_X = pd.DataFrame(data={'UserID':[3],'gameID':[6]})\n",
    "display(TDD_test_X)\n",
    "display(test_ratings_matrix)\n",
    "display(TDD_train_X)\n",
    "\n",
    "def test_baseline_predictor():\n",
    "    predictor = Base_Predictor()\n",
    "    predictor.fit(TDD_train_X[['UserID','gameID']],TDD_train_X.rating)\n",
    "    assert predictor._mean == 6.125, \"The incorrect mean was calculated for the baseline test set\"\n",
    "    assert predictor._bu.tolist() == [0.20833333333333304,-1.125,1.375], \"The wrong bu values were calculated for the baseline test\"\n",
    "    assert predictor._bi.tolist() == [0.05555555555555536, 0.05555555555555536, -0.16666666666666607], \"incorrect bi was calculated for baseline test\"\n",
    "    assert predictor.predict(TDD_test_X).tolist() == [7.333333333333334], \"baseline prediction for the test value was incorrect\"\n",
    "        \n",
    "\n",
    "test_baseline_predictor()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## User-User Collaborative Filtering\n",
    "\n",
    "This is the system described in section 2.2 of the linked paper. The idea is that to predict the rating of user U and item I, you use the normalized average rating of the N most similar users to U who have reviewed item I. There are multiple similarity measures that can be used, and several other hyper paramters that can be tweaked that can be fed into the class constructor for testing and comparison. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.2 s ± 167 ms per loop (mean ± std. dev. of 7 runs, 1 loop each)\n"
     ]
    }
   ],
   "source": [
    "train_X, test_x, train_y,test_y = train_test_split(elite[['UserID','gameID']],elite.rating,test_size=.3,random_state=42)\n",
    "predictor = U_U_predictor()\n",
    "predictor.fit(train_X,train_y)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.base import BaseEstimator, RegressorMixin\n",
    "\n",
    "class U_U_predictor(BaseEstimator, RegressorMixin):\n",
    "    \n",
    "    #ratings matrix from the actual training values\n",
    "    #_R \n",
    "    \n",
    "    #precomputing user's average ratings and std to save time later.\n",
    "    #_user_average_rating\n",
    "    #_user_standard_deviation\n",
    "    \n",
    "    #user similarity matrix (size user x user)\n",
    "    #_S\n",
    "    \n",
    "    #function that changes depending on selected similarity metric (cosine, pearson, spearman, etc.)\n",
    "    #_calculate_user_similarity\n",
    "    \n",
    "    #switches between equation 2.6 and 2.7 in the paper\n",
    "    #_normalize_to_z_scores\n",
    "    \n",
    "    #the paper suggests a dampening threshhold to keep users from sparse reviews getting rated as overly similar\n",
    "    #_pearson_threshold\n",
    "    \n",
    "    #how many nearest neighbors to look at when computing rating predictions\n",
    "    #_N_similar\n",
    "        \n",
    "    def __init__(self, similarity_type = 'pearson', normalize_to_z_scores=False, pearson_threshold=50,N_similar=20):\n",
    "        self._normalize_to_z_scores = normalize_to_z_scores\n",
    "        self._pearson_threshold = pearson_threshold\n",
    "        self._N_similar = N_similar\n",
    "        if similarity_type=='cosine':\n",
    "            self._calculate_user_similarity = self._cosine_similarity\n",
    "        else: self._calculate_user_similarity = self._pearson_calculate_user_similarity\n",
    "            \n",
    "    def fit(self,X,y):\n",
    "        self._calculate_ratings_matrix(X,y)\n",
    "        self._calculate_user_similarity_matrix_s_vector()\n",
    "    \n",
    "    def _calculate_ratings_matrix(self, X,y):\n",
    "        self._R = pd.concat([X,y],axis=1).pivot_table(index='UserID',columns='gameID',values='rating')\n",
    "        \n",
    "        #preprocessing to make user similarities easier to calculate\n",
    "        self._user_average_rating = self._R.mean(axis=1)\n",
    "        self._user_standard_deviation = self._R.std(axis=1)\n",
    "        \n",
    "    def _calculate_user_similarity_matrix_s_vector(self):\n",
    "        #initialize our similarity matrix _S, and our temp numpy matrix we'll be using while calculating.\n",
    "        self._S = pd.DataFrame(index=self._R.index, columns = self._R.index.rename('User_Prime_ID'), data=0.0)\n",
    "        temp = np.full(self._S.shape,np.nan)\n",
    "        \n",
    "        #We have a user x user matrix of similarity values, but we don't need to do the main diagonal (user1 x user1\n",
    "        #will always have 1.0) and since the top and bottom diagonals are identical (since user1xuser2 = user2xuser1)\n",
    "        #we only bother calculating along the upper triangle. We go row by row, the row sizes decrease as we go.\n",
    "        for index,user1 in enumerate(self._R.index[:-1]):\n",
    "            user2s = self._R.index[index+1:]\n",
    "            temp[index,index+1:] = self._pearson_r_vector(user1,index,user2s)\n",
    "            \n",
    "        #now that we have the upper triangle values, all we have to do is mirror it to the bottom and we're done.\n",
    "        i_lower = np.tril_indices(temp.shape[0], -1)\n",
    "        temp[i_lower] = temp.T[i_lower] \n",
    "        #turn our numpy temp matrix back into a dataframe.\n",
    "        self._S = pd.DataFrame(temp, columns=self._S.columns, index=self._S.index)\n",
    "            \n",
    "    def _pearson_r_vector(self,user1,user1_index,user2s):\n",
    "        \"\"\"Vectorized implementation of the user x user algorithm. User1 is a single value, index is where user1 appears\n",
    "        in the list, and user2s is a vector of all the users that follow User1.\"\"\"\n",
    "        #get the average for user 1, and a vector of averages for all the other users.\n",
    "        user1_average = self._user_average_rating[user1]\n",
    "        user2_averages = self._user_average_rating[user1_index+1:]\n",
    "        \n",
    "        #find where user1 and user2s have reviewed items. (left half is a bool vector, right is a bool matrix).\n",
    "        #End matrix has each row as a boolean vector showing which items both user1 and the user2 for that row reviewed  \n",
    "        #We're reversing since we want False where both users reviewed the same item, and True elsewhere.\n",
    "        mask = ~(self._R.iloc[user1_index].notnull().as_matrix() & self._R.iloc[user1_index+1:].notnull().as_matrix())\n",
    "\n",
    "        #Turns out working directly with numpy matrixes is faster, so that's what I do from here on out.\n",
    "        #First, null out any item reviews for user2s where user1 didn't have a review.\n",
    "        user2_ratings = self._R.iloc[user1_index+1:].as_matrix()\n",
    "        user2_ratings[mask] = np.NaN\n",
    "        \n",
    "        #now we get a matrix of user1 reviews. Each row corresponds to one of the users in user2s, with all reviews\n",
    "        #nulled except for items both user1 and the user in that row of user2s reviewed.\n",
    "        user1_ratings = np.full(user2_ratings.shape,np.NaN)\n",
    "        user1_base_ratings = self._R.iloc[user1_index].as_matrix()\n",
    "        for i in range(user1_ratings.shape[0]):\n",
    "            user1_ratings[i] = user1_base_ratings\n",
    "            user1_ratings[i, mask[i]] = np.NaN\n",
    "            \n",
    "        #normalize by mean. Turns out subtracting a column vector from a matrix is fussy in numpy.\n",
    "        user1_ratings -= user1_average\n",
    "        user2_ratings = np.subtract(user2_ratings, user2_averages.values.reshape(-1,1))\n",
    "        \n",
    "        #now that we have our normalized reviews, for computational convenience I'm turning NaNs to 0s.\n",
    "        nullmask = np.isnan(user1_ratings)\n",
    "        user1_ratings[nullmask] = 0.0\n",
    "        user2_ratings[nullmask] = 0.0\n",
    "        \n",
    "        #pearsonr is cov(1,2)/sqrt(Var(1)*Var(2)). This is just a vectorized implementation, doing row-wise dot \n",
    "        #products between two vectors.\n",
    "        variance1 = (user1_ratings * user1_ratings).sum(axis=1)\n",
    "        variance2 = (user2_ratings * user2_ratings).sum(axis=1)\n",
    "        denom = np.sqrt(variance1*variance2)\n",
    "        covariance = (user1_ratings * user2_ratings).sum(axis=1)\n",
    "\n",
    "        #catch any divide by 0 errors. Any user2s with 0 variance will produce a NaN.\n",
    "        with np.errstate(divide='ignore',invalid='ignore'):\n",
    "            ret = covariance/denom\n",
    "            ret[np.isnan(ret)] = 0.0\n",
    "            \n",
    "        return ret\n",
    "        \n",
    "    def _cosine_similarity(self):\n",
    "        pass\n",
    "    \n",
    "    def _find_N_similar_users(self, user1,user2):\n",
    "        pass\n",
    "    \n",
    "    def _find_items_two_users_both_reviewed(self, user1,user2):\n",
    "        return self._items_reviewed[user1].intersection(self._items_reviewed[user2])\n",
    "    \n",
    "    def predict(self,X):\n",
    "        return X.apply(lambda row: self._single_prediction(row), axis=1).values\n",
    "        \n",
    "    def _single_prediction(self, row):\n",
    "        user_mean = self._user_average_rating[row.UserID]\n",
    "        N = self._N_similar\n",
    "    \n",
    "        #nearest users IDs are the index of this series, s(u,u') is the values. It's filtered so only users\n",
    "        #who have also rated the game in question are considered. \n",
    "        N_nearest_similar = self._S[row.UserID][self._R[row.gameID].notnull()].nlargest(N)\n",
    "    \n",
    "        #vectors for most similar user information\n",
    "        similar_users_means = self._user_average_rating[N_nearest_similar.index].values\n",
    "        similar_users_item_ratings = self._R.loc[N_nearest_similar.index, row.gameID].values\n",
    "    \n",
    "        user_std = 1.0\n",
    "        similar_users_stds = np.full(N,1.0)\n",
    "        if(self._normalize_to_z_scores):\n",
    "            user_std = self._user_standard_deviation[row.UserID]\n",
    "            similar_users_stds = self._user_standard_deviation[N_nearest_similar.index].values\n",
    "    \n",
    "        similar_users_z_values = (similar_users_item_ratings-similar_users_means)/similar_users_stds\n",
    "        prediction = user_mean + ((user_std/N) * np.dot(N_nearest_similar.values,similar_users_z_values))\n",
    "    \n",
    "        return prediction\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "train_X, test_x, train_y,test_y = train_test_split(elite[['UserID','gameID']],elite.rating,test_size=.3,random_state=42)\n",
    "def test_user_user_similarity_matrix():\n",
    "    predictor = U_U_predictor()\n",
    "    predictor.fit(train_X,train_y)\n",
    "    \n",
    "    S = pd.read_pickle('user_S')\n",
    "    #display(S.equals(predictor._S))\n",
    "    display(S.head())\n",
    "    \n",
    "def profile_pearson_r():\n",
    "    test_row = pd.Series(data={'UserID':272.0,'User_Prime_ID':388.0,'rating':0})\n",
    "    predictor = U_U_predictor()\n",
    "    predictor._calculate_ratings_matrix(train_X,train_y)\n",
    "    predictor._pearson_calculate_user_similarity(test_row)\n",
    "\n",
    "\n",
    "test_pearson_r()\n",
    "#%lprun -f U_U_predictor._pearson_calculate_user_similarity profile_pearson_r()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>User_Prime_ID</th>\n",
       "      <th>272</th>\n",
       "      <th>388</th>\n",
       "      <th>430</th>\n",
       "      <th>2044</th>\n",
       "      <th>3080</th>\n",
       "      <th>3256</th>\n",
       "      <th>3557</th>\n",
       "      <th>5038</th>\n",
       "      <th>5217</th>\n",
       "      <th>5480</th>\n",
       "      <th>...</th>\n",
       "      <th>180167</th>\n",
       "      <th>180775</th>\n",
       "      <th>181123</th>\n",
       "      <th>181339</th>\n",
       "      <th>181472</th>\n",
       "      <th>187094</th>\n",
       "      <th>189973</th>\n",
       "      <th>191116</th>\n",
       "      <th>192057</th>\n",
       "      <th>193339</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>UserID</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>272</th>\n",
       "      <td>NaN</td>\n",
       "      <td>-0.056713</td>\n",
       "      <td>0.042577</td>\n",
       "      <td>-0.083717</td>\n",
       "      <td>0.006745</td>\n",
       "      <td>-0.150557</td>\n",
       "      <td>-0.013788</td>\n",
       "      <td>-0.178553</td>\n",
       "      <td>-0.064375</td>\n",
       "      <td>-0.126510</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.179775</td>\n",
       "      <td>-0.081585</td>\n",
       "      <td>-0.050838</td>\n",
       "      <td>-0.101766</td>\n",
       "      <td>-0.118772</td>\n",
       "      <td>-0.077584</td>\n",
       "      <td>0.082922</td>\n",
       "      <td>0.011729</td>\n",
       "      <td>-0.095787</td>\n",
       "      <td>-0.074771</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>388</th>\n",
       "      <td>-0.056713</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.046515</td>\n",
       "      <td>0.153163</td>\n",
       "      <td>0.097794</td>\n",
       "      <td>0.197996</td>\n",
       "      <td>0.285074</td>\n",
       "      <td>0.177844</td>\n",
       "      <td>0.293407</td>\n",
       "      <td>0.350157</td>\n",
       "      <td>...</td>\n",
       "      <td>0.036938</td>\n",
       "      <td>0.208991</td>\n",
       "      <td>0.371450</td>\n",
       "      <td>0.189091</td>\n",
       "      <td>0.320189</td>\n",
       "      <td>0.261483</td>\n",
       "      <td>-0.058570</td>\n",
       "      <td>0.348025</td>\n",
       "      <td>0.142535</td>\n",
       "      <td>0.224021</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>430</th>\n",
       "      <td>0.042577</td>\n",
       "      <td>0.046515</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.234026</td>\n",
       "      <td>0.097142</td>\n",
       "      <td>0.140773</td>\n",
       "      <td>0.321387</td>\n",
       "      <td>0.087036</td>\n",
       "      <td>0.087268</td>\n",
       "      <td>0.201068</td>\n",
       "      <td>...</td>\n",
       "      <td>0.107156</td>\n",
       "      <td>0.285411</td>\n",
       "      <td>0.265436</td>\n",
       "      <td>0.290484</td>\n",
       "      <td>0.087081</td>\n",
       "      <td>0.095054</td>\n",
       "      <td>0.263194</td>\n",
       "      <td>0.042129</td>\n",
       "      <td>0.173206</td>\n",
       "      <td>0.265883</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2044</th>\n",
       "      <td>-0.083717</td>\n",
       "      <td>0.153163</td>\n",
       "      <td>0.234026</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.434913</td>\n",
       "      <td>0.340015</td>\n",
       "      <td>0.420451</td>\n",
       "      <td>0.290227</td>\n",
       "      <td>0.036390</td>\n",
       "      <td>0.310784</td>\n",
       "      <td>...</td>\n",
       "      <td>0.344774</td>\n",
       "      <td>0.354660</td>\n",
       "      <td>0.358454</td>\n",
       "      <td>0.300479</td>\n",
       "      <td>0.251006</td>\n",
       "      <td>0.209808</td>\n",
       "      <td>0.319423</td>\n",
       "      <td>0.041889</td>\n",
       "      <td>0.065291</td>\n",
       "      <td>0.186324</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3080</th>\n",
       "      <td>0.006745</td>\n",
       "      <td>0.097794</td>\n",
       "      <td>0.097142</td>\n",
       "      <td>0.434913</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.240520</td>\n",
       "      <td>0.436059</td>\n",
       "      <td>0.127337</td>\n",
       "      <td>-0.014994</td>\n",
       "      <td>0.300714</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000822</td>\n",
       "      <td>0.170800</td>\n",
       "      <td>0.327374</td>\n",
       "      <td>0.256311</td>\n",
       "      <td>0.029283</td>\n",
       "      <td>0.218664</td>\n",
       "      <td>0.167901</td>\n",
       "      <td>-0.068388</td>\n",
       "      <td>0.179503</td>\n",
       "      <td>0.360398</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 199 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "User_Prime_ID    272       388       430       2044      3080      3256    \\\n",
       "UserID                                                                      \n",
       "272                 NaN -0.056713  0.042577 -0.083717  0.006745 -0.150557   \n",
       "388           -0.056713       NaN  0.046515  0.153163  0.097794  0.197996   \n",
       "430            0.042577  0.046515       NaN  0.234026  0.097142  0.140773   \n",
       "2044          -0.083717  0.153163  0.234026       NaN  0.434913  0.340015   \n",
       "3080           0.006745  0.097794  0.097142  0.434913       NaN  0.240520   \n",
       "\n",
       "User_Prime_ID    3557      5038      5217      5480      ...       180167  \\\n",
       "UserID                                                   ...                \n",
       "272           -0.013788 -0.178553 -0.064375 -0.126510    ...    -0.179775   \n",
       "388            0.285074  0.177844  0.293407  0.350157    ...     0.036938   \n",
       "430            0.321387  0.087036  0.087268  0.201068    ...     0.107156   \n",
       "2044           0.420451  0.290227  0.036390  0.310784    ...     0.344774   \n",
       "3080           0.436059  0.127337 -0.014994  0.300714    ...     0.000822   \n",
       "\n",
       "User_Prime_ID    180775    181123    181339    181472    187094    189973  \\\n",
       "UserID                                                                      \n",
       "272           -0.081585 -0.050838 -0.101766 -0.118772 -0.077584  0.082922   \n",
       "388            0.208991  0.371450  0.189091  0.320189  0.261483 -0.058570   \n",
       "430            0.285411  0.265436  0.290484  0.087081  0.095054  0.263194   \n",
       "2044           0.354660  0.358454  0.300479  0.251006  0.209808  0.319423   \n",
       "3080           0.170800  0.327374  0.256311  0.029283  0.218664  0.167901   \n",
       "\n",
       "User_Prime_ID    191116    192057    193339  \n",
       "UserID                                       \n",
       "272            0.011729 -0.095787 -0.074771  \n",
       "388            0.348025  0.142535  0.224021  \n",
       "430            0.042129  0.173206  0.265883  \n",
       "2044           0.041889  0.065291  0.186324  \n",
       "3080          -0.068388  0.179503  0.360398  \n",
       "\n",
       "[5 rows x 199 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "    S = pd.read_pickle('user_S')\n",
    "    display(S.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 2min 57s, sys: 496 ms, total: 2min 58s\n",
      "Wall time: 5min 7s\n"
     ]
    }
   ],
   "source": [
    "#was 189 seconds\n",
    "#was 97 seconds. \n",
    "#was 49 seconds\n",
    "#calling it good at 3.1 seconds\n",
    "\n",
    "train_X, test_x, train_y,test_y = train_test_split(frequent[['UserID','gameID']],frequent.rating,test_size=.3,random_state=42)\n",
    "\n",
    "\n",
    "predictor = U_U_predictor()\n",
    "#%lprun -f predictor.fit predictor.fit(train_X,train_y)\n",
    "%time predictor.fit(train_X,train_y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Selection and Error checking\n",
    "\n",
    "Now that I've gotten some models built out, I can use Sklearn's framework to check out different prediction systems, compare RMSE, and see what kind of model works the best with this dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.32964534833\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "#predictor = Base_Predictor()\n",
    "#train_X, test_x, train_y,test_y = train_test_split(elite[['UserID','gameID']],elite.rating,test_size=.3,random_state=42)\n",
    "#predictor.fit(train_X,train_y)\n",
    "\n",
    "predictions = predictor.predict(test_x)\n",
    "\n",
    "mse = mean_squared_error(predictions,test_y)\n",
    "print(np.sqrt(mse))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.31049914233\n"
     ]
    }
   ],
   "source": [
    "predictor = U_U_predictor(normalize_to_z_scores=True, N_similar=10)\n",
    "predictor.fit(train_X,train_y)\n",
    "\n",
    "predict = predictor.predict(test_X)\n",
    "\n",
    "mse = mean_squared_error(predict,test_y)\n",
    "print(np.sqrt(mse))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.30633111229\n"
     ]
    }
   ],
   "source": [
    "predictor = U_U_predictor(normalize_to_z_scores=True, N_similar=5)\n",
    "predictor.fit(train_X,train_y)\n",
    "\n",
    "predict = predictor.predict(test_X)\n",
    "\n",
    "mse = mean_squared_error(predict,test_y)\n",
    "print(np.sqrt(mse))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.31054160406\n"
     ]
    }
   ],
   "source": [
    "predictor = U_U_predictor(normalize_to_z_scores=True, N_similar=3)\n",
    "predictor.fit(train_X,train_y)\n",
    "\n",
    "predict = predictor.predict(test_X)\n",
    "\n",
    "mse = mean_squared_error(predict,test_y)\n",
    "print(np.sqrt(mse))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.30322536673\n"
     ]
    }
   ],
   "source": [
    "predictor = Base_Predictor()\n",
    "predictor.fit(train_X,train_y)\n",
    "\n",
    "predictions = predictor.predict(test_x)\n",
    "\n",
    "mse = mean_squared_error(predictions,test_y)\n",
    "print(np.sqrt(mse))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
