{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Implementing Recommender Systems for BoardGamesGeek.com"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "from IPython.display import display\n",
    "%matplotlib inline\n",
    "#line-by-line runtime comparison for easier code optimization.\n",
    "%load_ext line_profiler\n",
    "\n",
    "pd.set_option('display.max_rows',1000)\n",
    "\n",
    "elite = pd.read_csv('../inputs/boardgame-elite-users.csv')\n",
    "elite = elite.rename(columns = {'Compiled from boardgamegeek.com by Matt Borthwick':'UserID'})\n",
    "titles = pd.read_csv('../inputs/boardgame-titles.csv')\n",
    "titles = titles.rename(columns={'boardgamegeek.com game ID':'gameID'})\n",
    "#frequent = pd.read_csv('../inputs/boardgame-frequent-users.csv')\n",
    "#frequent = frequent.rename(columns = {'Compiled from boardgamegeek.com by Matt Borthwick':'UserID'})\n",
    "#load up the big dataset\n",
    "#users = pd.read_csv('../inputs/boardgame-users.csv')\n",
    "#users = users.rename(columns = {'Compiled from boardgamegeek.com by Matt Borthwick':'UserID'})\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Baseline Predictor\n",
    "This is the simplest predictor I'm making for the project. It doubles as a way to normalize the Ratings matrix R for more complex algorithms (like SVD) that require some kind of a way to fill missing ratings in the sparse matrix. Subtracting the baseline prediction from each value in R normalizes so that missing values can be set to 0.\n",
    "\n",
    "All this prediction does is use the user rating averages, total average rating, and average item ratings to come up with a believable first guess. Details are in section 2.1 of the paper linked in the exploratory notebook. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.base import BaseEstimator, RegressorMixin\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "class Base_Predictor(BaseEstimator,RegressorMixin):\n",
    "    def __init__(self, DAMPENING_TERM=25, dampening=False):\n",
    "        self._dampening_term = 25\n",
    "        self._dampening = dampening\n",
    "        \n",
    "    def fit(self, X, y):\n",
    "        self._mean = y.mean()\n",
    "        self._R = pd.concat([X,y],axis=1).pivot_table(index='UserID',columns='gameID',values='rating')\n",
    "        self._bu = self._R.apply(lambda row: self._user_base(row), axis=1)\n",
    "        self._bi = self._R.apply(lambda column: self._item_base(column))\n",
    "        \n",
    "    def _user_base(self, row):\n",
    "        \"\"\"(1/M+d)*bu is with the dampening factor. Without it's 1/M * bu. To find the way to add the \n",
    "        dampening factor as a scalar multiplication: \n",
    "            k*1/M(bu) = 1/M+d(bu)\n",
    "            k = M/M+d\"\"\"\n",
    "        bu = row.mean() - self._mean\n",
    "        if self._dampening:\n",
    "            num_items_user_reviewed = row[row.notnull()].size\n",
    "            damp_factor = num_items_user_reviewed/(num_items_user_reviewed+self._dampening_term)\n",
    "            bu*=damp_factor\n",
    "        return bu\n",
    "    \n",
    "    def _item_base(self, column):\n",
    "        users_that_reviewed_this_item = column[column.notnull()]\n",
    "        bu_for_users_that_reviewed_i = self._bu[users_that_reviewed_this_item.index].mean()\n",
    "        bi = users_that_reviewed_this_item.mean()-bu_for_users_that_reviewed_i-self._mean\n",
    "        if self._dampening:\n",
    "            num_users_reviewed_item = column[column.notnull()].size\n",
    "            damp_factor = num_users_reviewed_item/(num_users_reviewed_item+self._dampening_term)\n",
    "            bi*=damp_factor\n",
    "        return bi\n",
    "        \n",
    "    def predict(self, X):\n",
    "        return self._mean + self._bu[X.UserID].values + self._bi[X.gameID].values\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### A little Unit Testing for Sanity's sake.\n",
    "I just made a simple 3x3 test data set with one missing value. I ran through the calculations by hand, and set up a little battery of tests to make sure it all works. I print out the 3 pieces of info so you can see visually. There's TDD_test_X, the user, item pair I predict. TDD_train_X is the list of values at the bottom, the middle matrix is TDD_test_X blown up into the ratings matrix (with the missing value I'm testing for showing). As long as this cell compiles without triggering an assertion error, things are working fine."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>UserID</th>\n",
       "      <th>gameID</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   UserID  gameID\n",
       "0       3       6"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>7</td>\n",
       "      <td>4</td>\n",
       "      <td>8.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5</td>\n",
       "      <td>7</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>7</td>\n",
       "      <td>8</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   4  5    6\n",
       "1  7  4  8.0\n",
       "2  5  7  3.0\n",
       "3  7  8  NaN"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>UserID</th>\n",
       "      <th>gameID</th>\n",
       "      <th>rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>7.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>8.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>7.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2</td>\n",
       "      <td>6</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>7.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>8.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   UserID  gameID  rating\n",
       "0       1       4     7.0\n",
       "1       1       5     4.0\n",
       "2       1       6     8.0\n",
       "3       2       4     5.0\n",
       "4       2       5     7.0\n",
       "5       2       6     3.0\n",
       "6       3       4     7.0\n",
       "7       3       5     8.0"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "np.random.seed(42)\n",
    "\n",
    "test_ratings_matrix = pd.DataFrame(np.random.randint(1,10,size=(3,3)),columns=map(int,list('456')),index=map(int,list('123')))\n",
    "test_ratings_matrix.loc[3,6] = np.NaN\n",
    "#collapse test frame down the same format as our dataset. 3 columns, user\n",
    "TDD_train_X = test_ratings_matrix.stack().reset_index()\n",
    "TDD_train_X.columns = ['UserID','gameID','rating']\n",
    "TDD_test_X = pd.DataFrame(data={'UserID':[3],'gameID':[6]})\n",
    "display(TDD_test_X)\n",
    "display(test_ratings_matrix)\n",
    "display(TDD_train_X)\n",
    "\n",
    "def test_baseline_predictor():\n",
    "    predictor = Base_Predictor()\n",
    "    predictor.fit(TDD_train_X[['UserID','gameID']],TDD_train_X.rating)\n",
    "    assert predictor._mean == 6.125, \"The incorrect mean was calculated for the baseline test set\"\n",
    "    assert predictor._bu.tolist() == [0.20833333333333304,-1.125,1.375], \"The wrong bu values were calculated for the baseline test\"\n",
    "    assert predictor._bi.tolist() == [0.05555555555555536, 0.05555555555555536, -0.16666666666666607], \"incorrect bi was calculated for baseline test\"\n",
    "    assert predictor.predict(TDD_test_X).tolist() == [7.333333333333334], \"baseline prediction for the test value was incorrect\"\n",
    "        \n",
    "\n",
    "test_baseline_predictor()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## User-User Collaborative Filtering\n",
    "\n",
    "This is the system described in section 2.2 of the linked paper. The idea is that to predict the rating of user U and item I, you use the normalized average rating of the N most similar users to U who have reviewed item I. There are multiple similarity measures that can be used, and several other hyper paramters that can be tweaked that can be fed into the class constructor for testing and comparison. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.base import BaseEstimator, RegressorMixin\n",
    "\n",
    "class U_U_predictor(BaseEstimator, RegressorMixin):\n",
    "    \n",
    "    #ratings matrix from the actual training values\n",
    "    #_R \n",
    "    \n",
    "    #precomputing user's average ratings and std to save time later.\n",
    "    #_user_average_rating\n",
    "    #_user_standard_deviation\n",
    "    \n",
    "    #user similarity matrix (size user x user)\n",
    "    #_S\n",
    "    \n",
    "    #function that changes depending on selected similarity metric (cosine, pearson, spearman, etc.)\n",
    "    #_calculate_user_similarity\n",
    "    \n",
    "    #switches between equation 2.6 and 2.7 in the paper\n",
    "    #_normalize_to_z_scores\n",
    "    \n",
    "    #the paper suggests a dampening threshhold to keep users from sparse reviews getting rated as overly similar\n",
    "    #_pearson_threshold\n",
    "    \n",
    "    #how many nearest neighbors to look at when computing rating predictions\n",
    "    #_N_similar\n",
    "        \n",
    "    def __init__(self, similarity_type = 'pearson', normalize_to_z_scores=False, pearson_threshold=50,N_similar=20):\n",
    "        self._normalize_to_z_scores = normalize_to_z_scores\n",
    "        self._pearson_threshold = pearson_threshold\n",
    "        self._N_similar = N_similar\n",
    "        if similarity_type=='cosine':\n",
    "            self._calculate_user_similarity = self._cosine_similarity\n",
    "        else: self._calculate_user_similarity = self._pearson_calculate_user_similarity\n",
    "            \n",
    "    def fit(self,X,y):\n",
    "        self._R = pd.concat([X,y],axis=1).pivot_table(index='UserID',columns='gameID',values='rating')\n",
    "        \n",
    "        #preprocessing to make user similarities easier to calculate\n",
    "        self._user_average_rating = self._R.mean(axis=1)\n",
    "        self._user_standard_deviation = self._R.std(axis=1)\n",
    "        self._calculate_item_lists(X)\n",
    "        \n",
    "        self._calculate_user_similarity_matrix_s()\n",
    "        \n",
    "    def _calculate_item_lists(self, X):\n",
    "        \"\"\"calculating user similarities is N^2, finding the intersection of two item lists from two users\n",
    "        is a very costly part of that. To speed things up, we're going through and calculating that list \n",
    "        once per user, moving that side of things from O(N^2) to O(N). This saved ~50% runtime for the inner loop.\"\"\"\n",
    "        self._items_reviewed = {}\n",
    "        \n",
    "        for user in X.UserID.unique().tolist():\n",
    "            ru = self._R.loc[user]\n",
    "            self._items_reviewed[user] = set(ru[ru.notnull()].index)    \n",
    "\n",
    "    def _calculate_user_similarity_matrix_s(self):    \n",
    "        \"\"\"All of the similarity measures I'm implementing are transitive (s(u,u') == s(u',u)) so I'm only calculating \n",
    "        one value for each pair once. If S is a UxU matrix, since you don't want to bother with calculating similarity \n",
    "        both for s(u,u') and s(u',u), that means we basically need to calculate values for only the upper triangle of \n",
    "        matrix S. We'll skip the main diagonal too, since we don't care about s(u,u). After calculating, we'll fill \n",
    "        out the matrix by mirroring the upper triangle down to the lower triangle to get our full matrix S.\"\"\"\n",
    "        \n",
    "        self._S = pd.DataFrame(index=self._R.index, columns = self._R.index.rename('User_Prime_ID'), data=0.0)\n",
    "        self._S = self._S.mask(np.tril(np.ones(self._S.shape, dtype=np.bool_)))\n",
    "        user_combinations = self._S.stack().reset_index()\n",
    "        user_combinations.columns = ['UserID','User_Prime_ID','rating']\n",
    "        \n",
    "        user_combinations.rating = user_combinations.apply(\n",
    "            lambda row: self._calculate_user_similarity(row), axis=1)\n",
    "        \n",
    "        temp_matrix = user_combinations.pivot_table(index='UserID',columns='User_Prime_ID',values='rating').as_matrix()\n",
    "        \n",
    "        #adding in left column and bottom row of NaNs so we can remap our new values to the upper and lower triangle\n",
    "        #of _S, and have all the indices match. \n",
    "        temp_matrix = np.append(np.full((temp_matrix.shape[0],1),np.NaN),temp_matrix,1)\n",
    "        temp_matrix = np.append(temp_matrix,np.full((1,temp_matrix.shape[1]),np.NaN),0)\n",
    "        \n",
    "        #mirror the upper triangle of matrix S (that we have values to) to the lower triangle to complete our matrix.\n",
    "        i_lower = np.tril_indices(temp_matrix.shape[0], -1)\n",
    "        temp_matrix[i_lower] = temp_matrix.T[i_lower] \n",
    "        self._S = pd.DataFrame(temp_matrix, columns=self._S.columns, index=self._S.index)\n",
    "        \n",
    "    def _pearson_calculate_user_similarity(self, row):\n",
    "        user1, user2 = row.UserID, row.User_Prime_ID\n",
    "        items_in_common = self._find_items_two_users_both_reviewed(user1, user2)\n",
    "        user1_average = self._user_average_rating[user1]\n",
    "        user2_average = self._user_average_rating[user2]\n",
    "        \n",
    "        user1_normalized_ratings = self._R.loc[user1, items_in_common] - user1_average\n",
    "        user2_normalized_ratings = self._R.loc[user2, items_in_common] - user2_average\n",
    "        \n",
    "        user1_norm = np.linalg.norm(user1_normalized_ratings)\n",
    "        user2_norm = np.linalg.norm(user2_normalized_ratings)\n",
    "        \n",
    "        #Rating vectors with very low standard deviation have very low norms using this formula. I'm tossing them\n",
    "        #out to prevent a divide by zero below. \n",
    "        if user1_norm < .0001 or user2_norm < .0001:\n",
    "            return 0.0\n",
    "        \n",
    "        corr = np.dot(user1_normalized_ratings, user2_normalized_ratings)/(user1_norm * user2_norm)\n",
    "        \n",
    "        dampening_factor = min((len(items_in_common)/self._pearson_threshold), 1.0)\n",
    "\n",
    "        return corr*dampening_factor\n",
    "\n",
    "    def _cosine_similarity(self):\n",
    "        pass\n",
    "    \n",
    "    def _find_N_similar_users(self, user1,user2):\n",
    "        pass\n",
    "    \n",
    "    def _find_items_two_users_both_reviewed(self, user1,user2):\n",
    "        return self._items_reviewed[user1].intersection(self._items_reviewed[user2])\n",
    "    \n",
    "    def predict(self,X):\n",
    "        return X.apply(lambda row: self._single_prediction(row), axis=1).values\n",
    "        \n",
    "    def _single_prediction(self, row):\n",
    "        user_mean = self._user_average_rating[row.UserID]\n",
    "        N = self._N_similar\n",
    "    \n",
    "        #nearest users IDs are the index of this series, s(u,u') is the values. It's filtered so only users\n",
    "        #who have also rated the game in question are considered. \n",
    "        N_nearest_similar = self._S[row.UserID][self._R[row.gameID].notnull()].nlargest(N)\n",
    "    \n",
    "        #vectors for most similar user information\n",
    "        similar_users_means = self._user_average_rating[N_nearest_similar.index].values\n",
    "        similar_users_item_ratings = self._R.loc[N_nearest_similar.index, row.gameID].values\n",
    "    \n",
    "        user_std = 1.0\n",
    "        similar_users_stds = np.full(N,1.0)\n",
    "        if(self._normalize_to_z_scores):\n",
    "            user_std = self._user_standard_deviation[row.UserID]\n",
    "            similar_users_stds = self._user_standard_deviation[N_nearest_similar.index].values\n",
    "    \n",
    "        similar_users_z_values = (similar_users_item_ratings-similar_users_means)/similar_users_stds\n",
    "        prediction = user_mean + ((user_std/N) * np.dot(N_nearest_similar.values,similar_users_z_values))\n",
    "    \n",
    "        return prediction\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_X, test_x, train_y,test_y = train_test_split(elite[['UserID','gameID']],elite.rating,test_size=.3,random_state=42)\n",
    "\n",
    "predictor = U_U_predictor()\n",
    "predictor.fit(train_X,train_y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Selection and Error checking\n",
    "\n",
    "Now that I've gotten some models built out, I can use Sklearn's framework to check out different prediction systems, compare RMSE, and see what kind of model works the best with this dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.32964534833\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "#predictor = Base_Predictor()\n",
    "#train_X, test_x, train_y,test_y = train_test_split(elite[['UserID','gameID']],elite.rating,test_size=.3,random_state=42)\n",
    "#predictor.fit(train_X,train_y)\n",
    "\n",
    "predictions = predictor.predict(test_x)\n",
    "\n",
    "mse = mean_squared_error(predictions,test_y)\n",
    "print(np.sqrt(mse))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.31049914233\n"
     ]
    }
   ],
   "source": [
    "predictor = U_U_predictor(normalize_to_z_scores=True, N_similar=10)\n",
    "predictor.fit(train_X,train_y)\n",
    "\n",
    "predict = predictor.predict(test_X)\n",
    "\n",
    "mse = mean_squared_error(predict,test_y)\n",
    "print(np.sqrt(mse))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.30633111229\n"
     ]
    }
   ],
   "source": [
    "predictor = U_U_predictor(normalize_to_z_scores=True, N_similar=5)\n",
    "predictor.fit(train_X,train_y)\n",
    "\n",
    "predict = predictor.predict(test_X)\n",
    "\n",
    "mse = mean_squared_error(predict,test_y)\n",
    "print(np.sqrt(mse))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.31054160406\n"
     ]
    }
   ],
   "source": [
    "predictor = U_U_predictor(normalize_to_z_scores=True, N_similar=3)\n",
    "predictor.fit(train_X,train_y)\n",
    "\n",
    "predict = predictor.predict(test_X)\n",
    "\n",
    "mse = mean_squared_error(predict,test_y)\n",
    "print(np.sqrt(mse))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "predictor = Base_Predictor()\n",
    "predictor.fit(train_X,train_y)\n",
    "\n",
    "predictions = predictor.predict(test_x)\n",
    "\n",
    "mse = mean_squared_error(predictions,test_y)\n",
    "print(np.sqrt(mse))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
